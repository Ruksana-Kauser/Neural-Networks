{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "216823a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd063784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>aug</td>\n",
       "      <td>sat</td>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>nov</td>\n",
       "      <td>tue</td>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0     mar  fri  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1     oct  tue  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2     oct  sat  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3     mar  fri  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4     mar  sun  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0  ...         0   \n",
       "..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...  ...       ...   \n",
       "512   aug  sun  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0  ...         0   \n",
       "513   aug  sun  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  ...         0   \n",
       "514   aug  sun  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  ...         0   \n",
       "515   aug  sat  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0  ...         0   \n",
       "516   nov  tue  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0  ...         0   \n",
       "\n",
       "     monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0           0         0         0         1         0         0         0   \n",
       "1           0         0         0         0         0         0         1   \n",
       "2           0         0         0         0         0         0         1   \n",
       "3           0         0         0         1         0         0         0   \n",
       "4           0         0         0         1         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         1         0   \n",
       "\n",
       "     monthsep  size_category  \n",
       "0           0          small  \n",
       "1           0          small  \n",
       "2           0          small  \n",
       "3           0          small  \n",
       "4           0          small  \n",
       "..        ...            ...  \n",
       "512         0          large  \n",
       "513         0          large  \n",
       "514         0          large  \n",
       "515         0          small  \n",
       "516         0          small  \n",
       "\n",
       "[517 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff_data = pd.read_csv('forestfires.csv')\n",
    "ff_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a988be34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.05959472e-01, -1.32332557e+00, -1.83047676e+00, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [-8.10203395e-03, -1.17954077e+00,  4.88890915e-01, ...,\n",
       "        -4.40225453e-02,  5.78503817e+00, -7.06081245e-01],\n",
       "       [-8.10203395e-03, -1.04982188e+00,  5.60715454e-01, ...,\n",
       "        -4.40225453e-02,  5.78503817e+00, -7.06081245e-01],\n",
       "       ...,\n",
       "       [-1.64008316e+00, -8.46647711e-01,  4.74768113e-01, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [ 6.80956663e-01,  5.49002541e-01,  2.69382214e-01, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [-2.02087875e+00, -1.68591332e+00, -1.78044169e+00, ...,\n",
       "         2.27156334e+01, -1.72859706e-01, -7.06081245e-01]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff_data_1 = ff_data.iloc[:,2:30]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "ff_data_norm = scaler.fit_transform(ff_data_1)\n",
    "ff_data_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4302c011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.76670947e+00, -1.32025451e+00, -8.43971398e-01, ...,\n",
       "        -6.53345819e-02,  4.98037274e-16, -2.73530281e-16],\n",
       "       [ 3.90786263e-01,  8.31061522e-01, -1.10136513e+00, ...,\n",
       "         3.42618601e-02, -9.55928328e-15,  1.15055466e-15],\n",
       "       [ 6.90415596e-01,  1.17774562e+00, -1.22199841e+00, ...,\n",
       "         2.63235187e-02,  2.58690766e-15, -5.66797432e-17],\n",
       "       ...,\n",
       "       [ 9.21634000e-01, -2.64543072e-01,  2.71921606e+00, ...,\n",
       "        -2.97865814e-01, -1.84247930e-16,  2.36645381e-16],\n",
       "       [-1.62054896e+00, -9.78838231e-01,  3.31987355e-01, ...,\n",
       "         3.91949863e-02, -2.30354869e-16,  2.72058887e-16],\n",
       "       [ 4.07590654e+00, -3.67440726e-01, -2.47151775e-01, ...,\n",
       "        -2.50420726e-02,  5.70142521e-17,  8.50237385e-17]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PCA\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=28)\n",
    "pca_values=pca.fit_transform(ff_data_norm)\n",
    "pca_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "958cd92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.35522746e-01, 6.85788793e-02, 6.23572652e-02, 5.32713255e-02,\n",
       "       4.75942360e-02, 4.68009902e-02, 4.37490015e-02, 4.28025164e-02,\n",
       "       4.08875728e-02, 4.01633268e-02, 3.92926854e-02, 3.83232321e-02,\n",
       "       3.64221503e-02, 3.63217289e-02, 3.57856782e-02, 3.50087806e-02,\n",
       "       3.35447704e-02, 3.24777366e-02, 3.04490902e-02, 3.00246758e-02,\n",
       "       2.37167400e-02, 2.08329788e-02, 1.18357869e-02, 8.88449559e-03,\n",
       "       4.55347471e-03, 7.98135931e-04, 2.67271490e-32, 1.95971390e-33])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = pca.explained_variance_ratio_\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b99fbbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.55, 20.41, 26.65, 31.98, 36.74, 41.42, 45.79, 50.07, 54.16,\n",
       "       58.18, 62.11, 65.94, 69.58, 73.21, 76.79, 80.29, 83.64, 86.89,\n",
       "       89.93, 92.93, 95.3 , 97.38, 98.56, 99.45, 99.91, 99.99, 99.99,\n",
       "       99.99])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var1 = np.cumsum(np.round(var,decimals=4)*100)\n",
    "var1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52ceac8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d88a921fd0>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(var1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a64548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hence here we will choose 24 pcs outoff 28 for further procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b30b9ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc1</th>\n",
       "      <th>pc2</th>\n",
       "      <th>pc3</th>\n",
       "      <th>pc4</th>\n",
       "      <th>pc5</th>\n",
       "      <th>pc6</th>\n",
       "      <th>pc7</th>\n",
       "      <th>pc8</th>\n",
       "      <th>pc9</th>\n",
       "      <th>pc10</th>\n",
       "      <th>...</th>\n",
       "      <th>pc16</th>\n",
       "      <th>pc17</th>\n",
       "      <th>pc18</th>\n",
       "      <th>pc19</th>\n",
       "      <th>pc20</th>\n",
       "      <th>pc21</th>\n",
       "      <th>pc22</th>\n",
       "      <th>pc23</th>\n",
       "      <th>pc24</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.766709</td>\n",
       "      <td>-1.320255</td>\n",
       "      <td>-0.843971</td>\n",
       "      <td>-1.994738</td>\n",
       "      <td>-1.453359</td>\n",
       "      <td>0.693985</td>\n",
       "      <td>0.308104</td>\n",
       "      <td>-0.019764</td>\n",
       "      <td>0.010161</td>\n",
       "      <td>-0.437314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197543</td>\n",
       "      <td>-0.021839</td>\n",
       "      <td>0.688958</td>\n",
       "      <td>0.563603</td>\n",
       "      <td>-0.439596</td>\n",
       "      <td>-0.926619</td>\n",
       "      <td>-0.405425</td>\n",
       "      <td>-0.118719</td>\n",
       "      <td>-0.017933</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.390786</td>\n",
       "      <td>0.831062</td>\n",
       "      <td>-1.101365</td>\n",
       "      <td>1.400671</td>\n",
       "      <td>2.869388</td>\n",
       "      <td>0.965898</td>\n",
       "      <td>-2.795574</td>\n",
       "      <td>0.041095</td>\n",
       "      <td>-0.548879</td>\n",
       "      <td>0.104500</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.503167</td>\n",
       "      <td>0.499649</td>\n",
       "      <td>0.563706</td>\n",
       "      <td>-0.703319</td>\n",
       "      <td>-1.535718</td>\n",
       "      <td>-0.892995</td>\n",
       "      <td>0.836590</td>\n",
       "      <td>0.204975</td>\n",
       "      <td>0.290771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.690416</td>\n",
       "      <td>1.177746</td>\n",
       "      <td>-1.221998</td>\n",
       "      <td>2.442038</td>\n",
       "      <td>1.090630</td>\n",
       "      <td>0.390801</td>\n",
       "      <td>-1.586675</td>\n",
       "      <td>-2.159336</td>\n",
       "      <td>-0.090580</td>\n",
       "      <td>0.260888</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.545144</td>\n",
       "      <td>-0.658411</td>\n",
       "      <td>-0.423618</td>\n",
       "      <td>0.860550</td>\n",
       "      <td>-1.195230</td>\n",
       "      <td>-0.297870</td>\n",
       "      <td>0.743648</td>\n",
       "      <td>0.081757</td>\n",
       "      <td>0.345915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.359951</td>\n",
       "      <td>-1.161443</td>\n",
       "      <td>0.385728</td>\n",
       "      <td>-2.118328</td>\n",
       "      <td>-1.949601</td>\n",
       "      <td>1.027664</td>\n",
       "      <td>-0.179422</td>\n",
       "      <td>-0.250227</td>\n",
       "      <td>-0.620329</td>\n",
       "      <td>-1.343189</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040887</td>\n",
       "      <td>0.017843</td>\n",
       "      <td>0.332572</td>\n",
       "      <td>1.164745</td>\n",
       "      <td>-1.632741</td>\n",
       "      <td>-0.817618</td>\n",
       "      <td>1.523710</td>\n",
       "      <td>-0.342302</td>\n",
       "      <td>-0.378420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.974329</td>\n",
       "      <td>-0.842626</td>\n",
       "      <td>1.327788</td>\n",
       "      <td>0.038086</td>\n",
       "      <td>-1.124763</td>\n",
       "      <td>-0.574676</td>\n",
       "      <td>-0.777155</td>\n",
       "      <td>0.303635</td>\n",
       "      <td>0.861126</td>\n",
       "      <td>-2.024719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844431</td>\n",
       "      <td>1.014944</td>\n",
       "      <td>-0.618231</td>\n",
       "      <td>0.822853</td>\n",
       "      <td>-1.794109</td>\n",
       "      <td>-0.723371</td>\n",
       "      <td>2.020419</td>\n",
       "      <td>-0.545591</td>\n",
       "      <td>0.161735</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>-0.087560</td>\n",
       "      <td>0.153964</td>\n",
       "      <td>1.241810</td>\n",
       "      <td>1.536581</td>\n",
       "      <td>0.372425</td>\n",
       "      <td>-1.133422</td>\n",
       "      <td>-0.362287</td>\n",
       "      <td>0.766946</td>\n",
       "      <td>0.818745</td>\n",
       "      <td>-0.289632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300522</td>\n",
       "      <td>0.513876</td>\n",
       "      <td>0.539642</td>\n",
       "      <td>-0.052958</td>\n",
       "      <td>1.898628</td>\n",
       "      <td>-1.441786</td>\n",
       "      <td>-0.821192</td>\n",
       "      <td>-1.205707</td>\n",
       "      <td>-0.698666</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>0.794366</td>\n",
       "      <td>-0.083966</td>\n",
       "      <td>2.670485</td>\n",
       "      <td>0.284995</td>\n",
       "      <td>0.223323</td>\n",
       "      <td>-0.904232</td>\n",
       "      <td>-0.014849</td>\n",
       "      <td>0.107226</td>\n",
       "      <td>1.340049</td>\n",
       "      <td>-0.147246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342367</td>\n",
       "      <td>0.485571</td>\n",
       "      <td>0.580150</td>\n",
       "      <td>0.384984</td>\n",
       "      <td>0.086251</td>\n",
       "      <td>-0.970693</td>\n",
       "      <td>-1.353365</td>\n",
       "      <td>-1.254890</td>\n",
       "      <td>-1.212175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>0.921634</td>\n",
       "      <td>-0.264543</td>\n",
       "      <td>2.719216</td>\n",
       "      <td>-0.019643</td>\n",
       "      <td>0.242195</td>\n",
       "      <td>-0.966939</td>\n",
       "      <td>-0.118080</td>\n",
       "      <td>0.123010</td>\n",
       "      <td>1.290364</td>\n",
       "      <td>-0.177553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332816</td>\n",
       "      <td>0.344047</td>\n",
       "      <td>0.122409</td>\n",
       "      <td>0.313948</td>\n",
       "      <td>0.211157</td>\n",
       "      <td>-0.777731</td>\n",
       "      <td>-1.736711</td>\n",
       "      <td>-1.154127</td>\n",
       "      <td>-1.230040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>-1.620549</td>\n",
       "      <td>-0.978838</td>\n",
       "      <td>0.331987</td>\n",
       "      <td>1.256638</td>\n",
       "      <td>-0.408164</td>\n",
       "      <td>0.735698</td>\n",
       "      <td>0.815510</td>\n",
       "      <td>-1.398344</td>\n",
       "      <td>0.076379</td>\n",
       "      <td>-0.005814</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011739</td>\n",
       "      <td>-1.035533</td>\n",
       "      <td>-0.774382</td>\n",
       "      <td>-0.216315</td>\n",
       "      <td>0.515791</td>\n",
       "      <td>0.080575</td>\n",
       "      <td>-0.055548</td>\n",
       "      <td>-0.067502</td>\n",
       "      <td>-0.311027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>4.075907</td>\n",
       "      <td>-0.367441</td>\n",
       "      <td>-0.247152</td>\n",
       "      <td>0.979966</td>\n",
       "      <td>6.792273</td>\n",
       "      <td>5.943666</td>\n",
       "      <td>-1.639583</td>\n",
       "      <td>8.121827</td>\n",
       "      <td>-0.627980</td>\n",
       "      <td>4.953722</td>\n",
       "      <td>...</td>\n",
       "      <td>10.467443</td>\n",
       "      <td>-7.333036</td>\n",
       "      <td>0.377340</td>\n",
       "      <td>8.870354</td>\n",
       "      <td>-1.074288</td>\n",
       "      <td>2.382433</td>\n",
       "      <td>1.042850</td>\n",
       "      <td>0.296436</td>\n",
       "      <td>0.125099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pc1       pc2       pc3       pc4       pc5       pc6       pc7  \\\n",
       "0    3.766709 -1.320255 -0.843971 -1.994738 -1.453359  0.693985  0.308104   \n",
       "1    0.390786  0.831062 -1.101365  1.400671  2.869388  0.965898 -2.795574   \n",
       "2    0.690416  1.177746 -1.221998  2.442038  1.090630  0.390801 -1.586675   \n",
       "3    3.359951 -1.161443  0.385728 -2.118328 -1.949601  1.027664 -0.179422   \n",
       "4    2.974329 -0.842626  1.327788  0.038086 -1.124763 -0.574676 -0.777155   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512 -0.087560  0.153964  1.241810  1.536581  0.372425 -1.133422 -0.362287   \n",
       "513  0.794366 -0.083966  2.670485  0.284995  0.223323 -0.904232 -0.014849   \n",
       "514  0.921634 -0.264543  2.719216 -0.019643  0.242195 -0.966939 -0.118080   \n",
       "515 -1.620549 -0.978838  0.331987  1.256638 -0.408164  0.735698  0.815510   \n",
       "516  4.075907 -0.367441 -0.247152  0.979966  6.792273  5.943666 -1.639583   \n",
       "\n",
       "          pc8       pc9      pc10  ...       pc16      pc17      pc18  \\\n",
       "0   -0.019764  0.010161 -0.437314  ...  -0.197543 -0.021839  0.688958   \n",
       "1    0.041095 -0.548879  0.104500  ...  -2.503167  0.499649  0.563706   \n",
       "2   -2.159336 -0.090580  0.260888  ...  -2.545144 -0.658411 -0.423618   \n",
       "3   -0.250227 -0.620329 -1.343189  ...  -0.040887  0.017843  0.332572   \n",
       "4    0.303635  0.861126 -2.024719  ...   0.844431  1.014944 -0.618231   \n",
       "..        ...       ...       ...  ...        ...       ...       ...   \n",
       "512  0.766946  0.818745 -0.289632  ...   0.300522  0.513876  0.539642   \n",
       "513  0.107226  1.340049 -0.147246  ...   0.342367  0.485571  0.580150   \n",
       "514  0.123010  1.290364 -0.177553  ...   0.332816  0.344047  0.122409   \n",
       "515 -1.398344  0.076379 -0.005814  ...  -0.011739 -1.035533 -0.774382   \n",
       "516  8.121827 -0.627980  4.953722  ...  10.467443 -7.333036  0.377340   \n",
       "\n",
       "         pc19      pc20      pc21      pc22      pc23      pc24  size_category  \n",
       "0    0.563603 -0.439596 -0.926619 -0.405425 -0.118719 -0.017933              0  \n",
       "1   -0.703319 -1.535718 -0.892995  0.836590  0.204975  0.290771              0  \n",
       "2    0.860550 -1.195230 -0.297870  0.743648  0.081757  0.345915              0  \n",
       "3    1.164745 -1.632741 -0.817618  1.523710 -0.342302 -0.378420              0  \n",
       "4    0.822853 -1.794109 -0.723371  2.020419 -0.545591  0.161735              0  \n",
       "..        ...       ...       ...       ...       ...       ...            ...  \n",
       "512 -0.052958  1.898628 -1.441786 -0.821192 -1.205707 -0.698666              1  \n",
       "513  0.384984  0.086251 -0.970693 -1.353365 -1.254890 -1.212175              1  \n",
       "514  0.313948  0.211157 -0.777731 -1.736711 -1.154127 -1.230040              1  \n",
       "515 -0.216315  0.515791  0.080575 -0.055548 -0.067502 -0.311027              0  \n",
       "516  8.870354 -1.074288  2.382433  1.042850  0.296436  0.125099              0  \n",
       "\n",
       "[517 rows x 25 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldf = pd.concat([pd.DataFrame(pca_values[:,0:24],columns=['pc1','pc2','pc3','pc4','pc5','pc6','pc7',\n",
    "                                                             'pc8','pc9','pc10','pc11','pc12','pc13','pc14',\n",
    "                                                             'pc15','pc16','pc17','pc18','pc19','pc20','pc21',\n",
    "                                                             'pc22','pc23','pc24']), ff_data[['size_category']]],axis=1)\n",
    "finaldf.size_category.replace(('large','small'),(1,0),inplace=True)\n",
    "finaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6beee771",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data into x and y\n",
    "\n",
    "array=finaldf.values\n",
    "x=array[:,0:24]\n",
    "y=array[:,24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb1a4b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ee2fdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "37/37 [==============================] - 1s 11ms/step - loss: 0.7104 - accuracy: 0.4377 - val_loss: 0.7027 - val_accuracy: 0.4872\n",
      "Epoch 2/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.6398 - accuracy: 0.7091 - val_loss: 0.6752 - val_accuracy: 0.6090\n",
      "Epoch 3/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.5973 - accuracy: 0.7618 - val_loss: 0.6663 - val_accuracy: 0.6603\n",
      "Epoch 4/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.5670 - accuracy: 0.7784 - val_loss: 0.6653 - val_accuracy: 0.6731\n",
      "Epoch 5/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.5488 - accuracy: 0.7784 - val_loss: 0.6643 - val_accuracy: 0.6731\n",
      "Epoch 6/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.5326 - accuracy: 0.7784 - val_loss: 0.6686 - val_accuracy: 0.6731\n",
      "Epoch 7/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.5196 - accuracy: 0.7784 - val_loss: 0.6737 - val_accuracy: 0.6731\n",
      "Epoch 8/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.5093 - accuracy: 0.7784 - val_loss: 0.6741 - val_accuracy: 0.6731\n",
      "Epoch 9/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.5003 - accuracy: 0.7784 - val_loss: 0.6729 - val_accuracy: 0.6731\n",
      "Epoch 10/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4919 - accuracy: 0.7784 - val_loss: 0.6720 - val_accuracy: 0.6731\n",
      "Epoch 11/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4842 - accuracy: 0.7784 - val_loss: 0.6693 - val_accuracy: 0.6731\n",
      "Epoch 12/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4771 - accuracy: 0.7784 - val_loss: 0.6717 - val_accuracy: 0.6731\n",
      "Epoch 13/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.7784 - val_loss: 0.6715 - val_accuracy: 0.6795\n",
      "Epoch 14/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.7812 - val_loss: 0.6692 - val_accuracy: 0.6795\n",
      "Epoch 15/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4547 - accuracy: 0.7812 - val_loss: 0.6622 - val_accuracy: 0.6795\n",
      "Epoch 16/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7839 - val_loss: 0.6614 - val_accuracy: 0.6859\n",
      "Epoch 17/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7978 - val_loss: 0.6631 - val_accuracy: 0.6859\n",
      "Epoch 18/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.8006 - val_loss: 0.6668 - val_accuracy: 0.6923\n",
      "Epoch 19/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.8006 - val_loss: 0.6683 - val_accuracy: 0.6987\n",
      "Epoch 20/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.8006 - val_loss: 0.6664 - val_accuracy: 0.7051\n",
      "Epoch 21/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4208 - accuracy: 0.8033 - val_loss: 0.6718 - val_accuracy: 0.7051\n",
      "Epoch 22/50\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.4149 - accuracy: 0.8089 - val_loss: 0.6702 - val_accuracy: 0.7051\n",
      "Epoch 23/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4099 - accuracy: 0.8089 - val_loss: 0.6662 - val_accuracy: 0.7051\n",
      "Epoch 24/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8089 - val_loss: 0.6667 - val_accuracy: 0.7051\n",
      "Epoch 25/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3983 - accuracy: 0.8116 - val_loss: 0.6650 - val_accuracy: 0.6923\n",
      "Epoch 26/50\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.3923 - accuracy: 0.8144 - val_loss: 0.6646 - val_accuracy: 0.6923\n",
      "Epoch 27/50\n",
      "37/37 [==============================] - ETA: 0s - loss: 0.3862 - accuracy: 0.81 - 0s 5ms/step - loss: 0.3862 - accuracy: 0.8172 - val_loss: 0.6627 - val_accuracy: 0.6923\n",
      "Epoch 28/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3801 - accuracy: 0.8227 - val_loss: 0.6649 - val_accuracy: 0.6923\n",
      "Epoch 29/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3728 - accuracy: 0.8227 - val_loss: 0.6690 - val_accuracy: 0.7051\n",
      "Epoch 30/50\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.3665 - accuracy: 0.8255 - val_loss: 0.6652 - val_accuracy: 0.7051\n",
      "Epoch 31/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3622 - accuracy: 0.8366 - val_loss: 0.6703 - val_accuracy: 0.7051\n",
      "Epoch 32/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3560 - accuracy: 0.8283 - val_loss: 0.6720 - val_accuracy: 0.7051\n",
      "Epoch 33/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3498 - accuracy: 0.8366 - val_loss: 0.6720 - val_accuracy: 0.7179\n",
      "Epoch 34/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3437 - accuracy: 0.8421 - val_loss: 0.6721 - val_accuracy: 0.7244\n",
      "Epoch 35/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3361 - accuracy: 0.8504 - val_loss: 0.6719 - val_accuracy: 0.7179\n",
      "Epoch 36/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3319 - accuracy: 0.8615 - val_loss: 0.6770 - val_accuracy: 0.7115\n",
      "Epoch 37/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3250 - accuracy: 0.8504 - val_loss: 0.6764 - val_accuracy: 0.7244\n",
      "Epoch 38/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3193 - accuracy: 0.8670 - val_loss: 0.6770 - val_accuracy: 0.7179\n",
      "Epoch 39/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3137 - accuracy: 0.8587 - val_loss: 0.6831 - val_accuracy: 0.7179\n",
      "Epoch 40/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3107 - accuracy: 0.8615 - val_loss: 0.6858 - val_accuracy: 0.7308\n",
      "Epoch 41/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3047 - accuracy: 0.8753 - val_loss: 0.6881 - val_accuracy: 0.7372\n",
      "Epoch 42/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.3001 - accuracy: 0.8753 - val_loss: 0.6930 - val_accuracy: 0.7372\n",
      "Epoch 43/50\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2932 - accuracy: 0.8726 - val_loss: 0.6946 - val_accuracy: 0.7372\n",
      "Epoch 44/50\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 0.2954 - accuracy: 0.8781 - val_loss: 0.6961 - val_accuracy: 0.7372\n",
      "Epoch 45/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.2856 - accuracy: 0.8781 - val_loss: 0.6988 - val_accuracy: 0.7244\n",
      "Epoch 46/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.2784 - accuracy: 0.8864 - val_loss: 0.6981 - val_accuracy: 0.7308\n",
      "Epoch 47/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.2748 - accuracy: 0.8837 - val_loss: 0.7082 - val_accuracy: 0.7372\n",
      "Epoch 48/50\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 0.2706 - accuracy: 0.8920 - val_loss: 0.7032 - val_accuracy: 0.7372\n",
      "Epoch 49/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.2648 - accuracy: 0.8920 - val_loss: 0.7067 - val_accuracy: 0.7372\n",
      "Epoch 50/50\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 0.2598 - accuracy: 0.8975 - val_loss: 0.7089 - val_accuracy: 0.7372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d89585caf0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st Iteration\n",
    "model=Sequential()\n",
    "model.add(Dense(12,input_dim=24,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(x,y, validation_split=0.3,epochs=50,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbc2f385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 3ms/step - loss: 0.3906 - accuracy: 0.8530\n"
     ]
    }
   ],
   "source": [
    "#accuracy of model\n",
    "scores=model.evaluate(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d52361fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 85.30%\n"
     ]
    }
   ],
   "source": [
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2b1647a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 16ms/step - loss: 0.5767 - accuracy: 0.7562 - val_loss: 0.6569 - val_accuracy: 0.6731\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.5618 - accuracy: 0.7562 - val_loss: 0.6523 - val_accuracy: 0.6731\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5590 - accuracy: 0.7562 - val_loss: 0.6594 - val_accuracy: 0.6731\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5527 - accuracy: 0.7562 - val_loss: 0.6381 - val_accuracy: 0.6731\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5466 - accuracy: 0.7562 - val_loss: 0.6522 - val_accuracy: 0.6731\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5411 - accuracy: 0.7562 - val_loss: 0.6554 - val_accuracy: 0.6731\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5397 - accuracy: 0.7562 - val_loss: 0.6497 - val_accuracy: 0.6731\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5360 - accuracy: 0.7590 - val_loss: 0.6440 - val_accuracy: 0.6731\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5351 - accuracy: 0.7562 - val_loss: 0.6515 - val_accuracy: 0.6731\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.5293 - accuracy: 0.7590 - val_loss: 0.6400 - val_accuracy: 0.6795\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5257 - accuracy: 0.7590 - val_loss: 0.6482 - val_accuracy: 0.6795\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5235 - accuracy: 0.7590 - val_loss: 0.6459 - val_accuracy: 0.6795\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5187 - accuracy: 0.7590 - val_loss: 0.6352 - val_accuracy: 0.6795\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5143 - accuracy: 0.7590 - val_loss: 0.6465 - val_accuracy: 0.6795\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5119 - accuracy: 0.7590 - val_loss: 0.6414 - val_accuracy: 0.6795\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.5088 - accuracy: 0.7590 - val_loss: 0.6342 - val_accuracy: 0.6795\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.5042 - accuracy: 0.7645 - val_loss: 0.6205 - val_accuracy: 0.6795\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.5029 - accuracy: 0.7784 - val_loss: 0.6195 - val_accuracy: 0.6795\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.4983 - accuracy: 0.7784 - val_loss: 0.6173 - val_accuracy: 0.6795\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.4940 - accuracy: 0.7645 - val_loss: 0.6368 - val_accuracy: 0.6795\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.4894 - accuracy: 0.7784 - val_loss: 0.6211 - val_accuracy: 0.6795\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4854 - accuracy: 0.7812 - val_loss: 0.6340 - val_accuracy: 0.6795\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 0s 14ms/step - loss: 0.4834 - accuracy: 0.7784 - val_loss: 0.6418 - val_accuracy: 0.6795\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.4786 - accuracy: 0.7839 - val_loss: 0.6327 - val_accuracy: 0.6859\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.4762 - accuracy: 0.7867 - val_loss: 0.6456 - val_accuracy: 0.6859\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.4717 - accuracy: 0.7895 - val_loss: 0.6349 - val_accuracy: 0.6859\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 0s 11ms/step - loss: 0.4697 - accuracy: 0.7895 - val_loss: 0.6207 - val_accuracy: 0.6923\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.4653 - accuracy: 0.7895 - val_loss: 0.6286 - val_accuracy: 0.6923\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.4626 - accuracy: 0.7922 - val_loss: 0.6302 - val_accuracy: 0.6987\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 0s 10ms/step - loss: 0.4590 - accuracy: 0.7895 - val_loss: 0.7141 - val_accuracy: 0.6987\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.4521 - accuracy: 0.7922 - val_loss: 0.7792 - val_accuracy: 0.6987\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.4487 - accuracy: 0.7922 - val_loss: 0.7845 - val_accuracy: 0.6987\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.4461 - accuracy: 0.7922 - val_loss: 0.7854 - val_accuracy: 0.6987\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.4435 - accuracy: 0.7922 - val_loss: 0.7857 - val_accuracy: 0.6987\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.4378 - accuracy: 0.7950 - val_loss: 0.7715 - val_accuracy: 0.6987\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4344 - accuracy: 0.7978 - val_loss: 0.7751 - val_accuracy: 0.6987\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.4315 - accuracy: 0.7950 - val_loss: 0.7791 - val_accuracy: 0.7051\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.4344 - accuracy: 0.8006 - val_loss: 0.6938 - val_accuracy: 0.7051\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.4251 - accuracy: 0.8006 - val_loss: 0.8643 - val_accuracy: 0.7051\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.4233 - accuracy: 0.7978 - val_loss: 0.9330 - val_accuracy: 0.7051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d898297580>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2nd Iteration\n",
    "model1=Sequential()\n",
    "model1.add(Dense(12,input_dim=24,activation='sigmoid'))\n",
    "model1.add(Dense(8,activation='sigmoid'))\n",
    "model1.add(Dense(1,activation='relu'))\n",
    "model1.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model1.fit(x, y, validation_split=0.3, epochs=40, batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d23f6e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 4ms/step - loss: 0.5735 - accuracy: 0.7698\n",
      "accuracy: 76.98%\n"
     ]
    }
   ],
   "source": [
    "#model accuracy\n",
    "scores1=model1.evaluate(x,y)\n",
    "print(\"%s: %.2f%%\" % (model1.metrics_names[1], scores1[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70ec3bb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 18ms/step - loss: 2.2775 - accuracy: 0.7202 - val_loss: 2.9356 - val_accuracy: 0.5962\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 2.1896 - accuracy: 0.7285 - val_loss: 2.7511 - val_accuracy: 0.5897\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 2.1700 - accuracy: 0.7341 - val_loss: 2.8751 - val_accuracy: 0.5962\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 2.0251 - accuracy: 0.7396 - val_loss: 2.3615 - val_accuracy: 0.5962\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 1.5700 - accuracy: 0.7424 - val_loss: 2.0490 - val_accuracy: 0.5897\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1.2480 - accuracy: 0.7452 - val_loss: 2.0093 - val_accuracy: 0.5833\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1.1178 - accuracy: 0.7562 - val_loss: 1.9867 - val_accuracy: 0.5897\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1.0329 - accuracy: 0.7618 - val_loss: 1.9704 - val_accuracy: 0.6154\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 1.0078 - accuracy: 0.7673 - val_loss: 1.9725 - val_accuracy: 0.6090\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.9980 - accuracy: 0.7645 - val_loss: 2.0373 - val_accuracy: 0.6282\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.9651 - accuracy: 0.7701 - val_loss: 2.0252 - val_accuracy: 0.6282\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.9194 - accuracy: 0.7784 - val_loss: 2.0198 - val_accuracy: 0.6538\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 0s 12ms/step - loss: 0.8313 - accuracy: 0.7729 - val_loss: 1.7902 - val_accuracy: 0.6090\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.8056 - accuracy: 0.7562 - val_loss: 1.9446 - val_accuracy: 0.5833\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.7907 - accuracy: 0.7618 - val_loss: 1.9090 - val_accuracy: 0.6154\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.7800 - accuracy: 0.7812 - val_loss: 1.8933 - val_accuracy: 0.6603\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.7702 - accuracy: 0.7895 - val_loss: 1.8871 - val_accuracy: 0.6667\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.7625 - accuracy: 0.7867 - val_loss: 1.8834 - val_accuracy: 0.6667\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.7593 - accuracy: 0.7895 - val_loss: 1.8754 - val_accuracy: 0.6667\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - ETA: 0s - loss: 0.8403 - accuracy: 0.78 - 0s 7ms/step - loss: 0.7535 - accuracy: 0.7978 - val_loss: 1.8711 - val_accuracy: 0.6731\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.7498 - accuracy: 0.7978 - val_loss: 1.8699 - val_accuracy: 0.6731\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 0s 9ms/step - loss: 0.7452 - accuracy: 0.8006 - val_loss: 1.8721 - val_accuracy: 0.6731\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.7419 - accuracy: 0.8033 - val_loss: 1.8711 - val_accuracy: 0.6731\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.7397 - accuracy: 0.7950 - val_loss: 1.8718 - val_accuracy: 0.6795\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.7810 - accuracy: 0.8061 - val_loss: 1.8764 - val_accuracy: 0.6795\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.7796 - accuracy: 0.8033 - val_loss: 1.8644 - val_accuracy: 0.6859\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 0s 13ms/step - loss: 0.7714 - accuracy: 0.8033 - val_loss: 1.8650 - val_accuracy: 0.6859\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.7682 - accuracy: 0.8006 - val_loss: 1.8580 - val_accuracy: 0.6859\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 0s 18ms/step - loss: 0.7643 - accuracy: 0.8006 - val_loss: 1.8549 - val_accuracy: 0.6923\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.7615 - accuracy: 0.8006 - val_loss: 1.8525 - val_accuracy: 0.6923\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7700 - accuracy: 0.7950 - val_loss: 1.8551 - val_accuracy: 0.6859\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.7599 - accuracy: 0.7922 - val_loss: 1.7631 - val_accuracy: 0.6923\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 0s 17ms/step - loss: 0.7515 - accuracy: 0.7922 - val_loss: 1.7495 - val_accuracy: 0.7051\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.7486 - accuracy: 0.8089 - val_loss: 1.7483 - val_accuracy: 0.7051\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 0s 16ms/step - loss: 0.7454 - accuracy: 0.8033 - val_loss: 1.7475 - val_accuracy: 0.7051\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 0s 15ms/step - loss: 0.7442 - accuracy: 0.8061 - val_loss: 1.7467 - val_accuracy: 0.7051\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 0s 8ms/step - loss: 0.7413 - accuracy: 0.8061 - val_loss: 1.7478 - val_accuracy: 0.6987\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7393 - accuracy: 0.8061 - val_loss: 1.7469 - val_accuracy: 0.6923\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7403 - accuracy: 0.8061 - val_loss: 1.7498 - val_accuracy: 0.6987\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.7385 - accuracy: 0.8116 - val_loss: 1.7540 - val_accuracy: 0.6923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d89705c820>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3rd Iteration\n",
    "model2=Sequential()\n",
    "model2.add(Dense(12,input_dim=24,activation='relu'))\n",
    "model2.add(Dense(8,activation='relu'))\n",
    "model2.add(Dense(1,activation='relu'))\n",
    "model2.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model2.fit(x,y,epochs=40, validation_split=0.3,batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c84e9ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 5ms/step - loss: 1.0419 - accuracy: 0.7756\n",
      "accuracy: 77.56%\n"
     ]
    }
   ],
   "source": [
    "#model accuracy\n",
    "scores2=model2.evaluate(x,y)\n",
    "print(\"%s: %.2f%%\" % (model2.metrics_names[1], scores2[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef9c58d",
   "metadata": {},
   "source": [
    "###### best accuracy is 85.30%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
